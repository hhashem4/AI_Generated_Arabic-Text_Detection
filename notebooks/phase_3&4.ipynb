{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63zESuzmRDrG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install & Imports"
      ],
      "metadata": {
        "id": "IMMP-zHQRGXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets huggingface_hub regex nltk\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "import regex as re2\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "tibN6_O0RJnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFzM970HRPG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "4RVYzFcOReD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "hf_token = os.getenv(\"HF_TOKEN\")\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "cd9yEEjiRf0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"KFUPM-JRCAI/arabic-generated-abstracts\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "_LtU-0y2Rh5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all splits into one dataframe\n",
        "import pandas as pd\n",
        "\n",
        "splits = {\n",
        "    \"by_polishing\": dataset[\"by_polishing\"],\n",
        "    \"from_title\": dataset[\"from_title\"],\n",
        "    \"from_title_and_content\": dataset[\"from_title_and_content\"]\n",
        "}\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for split_name, split_data in splits.items():\n",
        "    temp_df = pd.DataFrame(split_data)\n",
        "\n",
        "    # Add a column indicating which split this example came from\n",
        "    temp_df[\"source_split\"] = split_name\n",
        "\n",
        "    # Create a proper target label column\n",
        "    # 1 = human-written\n",
        "    # 0 = AI-generated (we duplicate rows later)\n",
        "    temp_df[\"label\"] = 1   # original abstract is human\n",
        "\n",
        "    df_list.append(temp_df)\n",
        "\n",
        "# Create unified dataframe of human-written abstracts\n",
        "df_human = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(\"Human dataframe shape:\", df_human.shape)\n",
        "df_human.head()"
      ],
      "metadata": {
        "id": "IKBJOL3pR0Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert AI abstracts to standalone rows\n",
        "\n",
        "ai_rows = []\n",
        "\n",
        "for _, row in df_human.iterrows():\n",
        "    ai_models = [\n",
        "        (\"allam\", row[\"allam_generated_abstract\"]),\n",
        "        (\"jais\", row[\"jais_generated_abstract\"]),\n",
        "        (\"llama\", row[\"llama_generated_abstract\"]),\n",
        "        (\"openai\", row[\"openai_generated_abstract\"]),\n",
        "    ]\n",
        "\n",
        "    for model_name, text in ai_models:\n",
        "        ai_rows.append({\n",
        "            \"abstract_text\": text,\n",
        "            \"source_split\": row[\"source_split\"],\n",
        "            \"generated_by\": model_name,\n",
        "            \"label\": 0  # AI\n",
        "        })\n",
        "\n",
        "# Convert to dataframe\n",
        "df_ai = pd.DataFrame(ai_rows)\n",
        "\n",
        "# Create human dataframe in same structure\n",
        "df_h = pd.DataFrame({\n",
        "    \"abstract_text\": df_human[\"original_abstract\"],\n",
        "    \"source_split\": df_human[\"source_split\"],\n",
        "    \"generated_by\": \"human\",\n",
        "    \"label\": 1\n",
        "})\n",
        "\n",
        "# Final unified dataset\n",
        "df = pd.concat([df_h, df_ai], ignore_index=True)\n",
        "\n",
        "print(\"Final unified dataset shape:\", df.shape)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Oo9VuTVuZQj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHUjGTqnSEAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "-9KeCU9HV0-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing utilities\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1UpAke6iZ_wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_diacritics(text):\n",
        "    arabic_diacritics = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
        "    return re.sub(arabic_diacritics, '', text)\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"[^؀-ۿ ]+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "stemmer = ISRIStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text)\n",
        "    text = remove_diacritics(text)\n",
        "    text = normalize_arabic(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in arabic_stopwords]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "Awv8tC3XVrwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to the  dataset\n",
        "df[\"clean_text\"] = df[\"abstract_text\"].apply(preprocess_text)\n",
        "\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "Sm3sk5wqV7ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "WieyPwSgXQwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TOKENIZATION FUNCTIONS\n",
        "def simple_word_tokenize(text):\n",
        "    return re2.findall(r\"\\p{Arabic}+|\\w+|[^\\s\\w]\", text, flags=re2.VERSION1)\n",
        "\n",
        "def sentence_tokenize(text):\n",
        "    parts = re.split(r'(?<=[\\.\\?\\!\\u061F\\u061B])\\s+', text)\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "def paragraph_tokenize(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    paragraphs = re.split(r'\\s*\\n\\s*\\n\\s*', text.strip())\n",
        "    return [p.strip() for p in paragraphs if p.strip()]"
      ],
      "metadata": {
        "id": "jEH7W144WCyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#APPLY TOKEN + SENTENCE EXTRACTION\n",
        "df[\"tokens\"] = df[\"clean_text\"].apply(lambda t: [tok for tok in simple_word_tokenize(t) if tok.strip()])\n",
        "df[\"words\"] = df[\"tokens\"].apply(lambda toks: [tok for tok in toks if re.search(r'\\w', tok)])\n",
        "df[\"sentences\"] = df[\"abstract_text\"].apply(sentence_tokenize)\n",
        "df[\"paragraphs\"] = df[\"abstract_text\"].apply(paragraph_tokenize)"
      ],
      "metadata": {
        "id": "6Abch_pBXAyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Words from ORIGINAL abstract text =====\n",
        "df[\"tokens_raw\"] = df[\"abstract_text\"].apply(\n",
        "    lambda t: [tok for tok in simple_word_tokenize(t) if tok.strip()]\n",
        ")\n",
        "\n",
        "df[\"words_raw\"] = df[\"tokens_raw\"].apply(\n",
        "    lambda toks: [tok for tok in toks if re.search(r\"\\w\", tok)]\n",
        ")"
      ],
      "metadata": {
        "id": "xnNc-a6PNEKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#crating the required features"
      ],
      "metadata": {
        "id": "KNSyLkSi3dOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F3 — Digits / Characters\n",
        "df[\"f003_digits_over_C\"] = df[\"clean_text\"].apply(\n",
        "    lambda t: len(re.findall(r'\\d', str(t))) / len(str(t))\n",
        "    if len(str(t)) > 0 else 0\n",
        ")"
      ],
      "metadata": {
        "id": "ceWd4UsprqkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#feature 26:Number of Commas\n",
        "df[\"f026_commas\"] = df[\"abstract_text\"].apply(\n",
        "    lambda t: str(t).count(\",\") if isinstance(t, str) else 0\n",
        ")"
      ],
      "metadata": {
        "id": "2SMnW8So4OME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature 49 :Number of Arabic Particles\n",
        "arabic_particles = {\n",
        "    'من','إلى','عن','على','في','ب','ك','ل',\n",
        "    'و','أو','ثم','بل','لكن',\n",
        "    'لا','لم','لن','ما',\n",
        "    'هل','إن','إذا','أين','متى','كيف','كم','أيان',\n",
        "    'قد','لمّا','حتى','أن','إنّ','إذن'\n",
        "}\n",
        "\n",
        "df[\"f049_num_particles_raw\"] = df[\"words_raw\"].apply(\n",
        "    lambda words: sum(1 for w in words if w in arabic_particles)\n",
        "    if isinstance(words, list) else 0\n",
        ")"
      ],
      "metadata": {
        "id": "gEeS0WhI4ORl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature 72 : Count of Third-Person Pronouns\n",
        "third_person_pronouns = {\n",
        "    \"هو\",\"هي\",\"هم\",\"هما\",\"هن\",\n",
        "    \"ذلك\",\"تلك\",\"ذلكم\",\"ذلكما\",\"تلكم\"\n",
        "}\n",
        "\n",
        "df[\"f072_third_person_pronouns_raw\"] = df[\"words_raw\"].apply(\n",
        "    lambda words: sum(1 for w in words if w in third_person_pronouns)\n",
        "    if isinstance(words, list) else 0\n",
        ")\n"
      ],
      "metadata": {
        "id": "cqFe9uMa4OUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n"
      ],
      "metadata": {
        "id": "fgr3YAU8Ioqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentiment = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        ")"
      ],
      "metadata": {
        "id": "IjAe2ojuJ5Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create Polarity Function\n",
        "def polarity_of(sentence):\n",
        "    if not isinstance(sentence, str) or sentence.strip() == \"\":\n",
        "        return 0\n",
        "\n",
        "    result = sentiment(sentence[:512])[0][\"label\"]\n",
        "\n",
        "    if result == \"POS\":\n",
        "        return 1\n",
        "    elif result == \"NEG\":\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "-u45G195JnAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create Polarity Shift Frequency function\n",
        "def polarity_shift_frequency(sentences):\n",
        "    if not isinstance(sentences, list) or len(sentences) < 2:\n",
        "        return 0\n",
        "\n",
        "    polarities = [polarity_of(s) for s in sentences]\n",
        "\n",
        "    return sum(\n",
        "        1 for a, b in zip(polarities[:-1], polarities[1:])\n",
        "        if a != b\n",
        "    )\n"
      ],
      "metadata": {
        "id": "S-GjGE2xKrNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply feature 95 in sentece variable\n",
        "df[\"f095_polarity_shift\"] = df[\"sentences\"].apply(polarity_shift_frequency)\n"
      ],
      "metadata": {
        "id": "kBy-wWJeJWtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "2wvQzG2Gr6eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spliting Data"
      ],
      "metadata": {
        "id": "mMg4GKFsI3Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: Train 70%, Temp 30%\n",
        "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42, shuffle=True)\n",
        "\n",
        "# Second split: Temp 30% → 15% Validation, 15% Test\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42, shuffle=True)\n",
        "\n",
        "# Show sizes\n",
        "print(\"TOTAL:\", len(df))\n",
        "print(\"TRAIN:\", len(train_df))\n",
        "print(\"VAL:\", len(val_df))\n",
        "print(\"TEST:\", len(test_df))"
      ],
      "metadata": {
        "id": "-LHluDBWI2iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NK_tvrdPI2mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF Features from Cleaned Text\n",
        "\n"
      ],
      "metadata": {
        "id": "KBjprvLtF30L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FvQx1-FZIIiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF vectorizer for Arabic text\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,   # limit vocabulary\n",
        "    ngram_range=(1,2),   # unigrams + bigrams\n",
        "    analyzer='word'\n",
        ")\n",
        "\n",
        "# Fit only on training set\n",
        "tfidf_vectorizer.fit(train_df[\"clean_text\"])\n",
        "\n",
        "# Transform train/validation/test sets\n",
        "X_train_tfidf = tfidf_vectorizer.transform(train_df[\"clean_text\"])\n",
        "X_val_tfidf   = tfidf_vectorizer.transform(val_df[\"clean_text\"])\n",
        "X_test_tfidf  = tfidf_vectorizer.transform(test_df[\"clean_text\"])\n",
        "\n",
        "print(\"TF-IDF shapes:\")\n",
        "print(\"Train:\", X_train_tfidf.shape)\n",
        "print(\"Validation:\", X_val_tfidf.shape)\n",
        "print(\"Test:\", X_test_tfidf.shape)"
      ],
      "metadata": {
        "id": "5yw0qt2WF8L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76IoaLfUGFc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define X and y"
      ],
      "metadata": {
        "id": "vvrSPCKBJQFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target variable\n",
        "y_train = train_df[\"label\"]\n",
        "y_val   = val_df[\"label\"]\n",
        "y_test  = test_df[\"label\"]\n",
        "\n",
        "# Features: TF-IDF from clean_text\n",
        "X_train = X_train_tfidf\n",
        "X_val   = X_val_tfidf\n",
        "X_test  = X_test_tfidf\n",
        "\n",
        "print(\"X and y are ready for ML models.\")\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation:\", X_val.shape, y_val.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "rfrLVYe5YARL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.1 — Baseline Model  — Logistic Regression"
      ],
      "metadata": {
        "id": "iupWzu9At2j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize the model\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Train on training set\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred = lr_model.predict(X_val)\n",
        "\n",
        "# Evaluate on validation set\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report (Validation):\")\n",
        "print(classification_report(y_val, y_val_pred))"
      ],
      "metadata": {
        "id": "CJ9h7a5Dt3Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "# Predict on test set\n",
        "y_test_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nClassification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# Optional: confusion matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cAcdWWakFXuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYmjfzwPJnew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.2: Traditional ML Models\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ooyaZO-KAOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Dictionary to store models and results\n",
        "models = {}\n",
        "\n",
        "# -----------------------\n",
        "#Support Vector Machine (SVM)\n",
        "# -----------------------\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_svm = svm_model.predict(X_val)\n",
        "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, y_val_pred_svm))\n",
        "print(classification_report(y_val, y_val_pred_svm))\n",
        "\n",
        "models['SVM'] = svm_model\n",
        "\n",
        "# -----------------------\n",
        "#Random Forest\n",
        "# -----------------------\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "print(\"Random Forest Validation Accuracy:\", accuracy_score(y_val, y_val_pred_rf))\n",
        "print(classification_report(y_val, y_val_pred_rf))\n",
        "\n",
        "models['RandomForest'] = rf_model\n",
        "\n",
        "# -----------------------\n",
        "#XGBoost\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_xgb = xgb_model.predict(X_val)\n",
        "print(\"XGBoost Validation Accuracy:\", accuracy_score(y_val, y_val_pred_xgb))\n",
        "print(classification_report(y_val, y_val_pred_xgb))\n",
        "\n",
        "models['XGBoost'] = xgb_model"
      ],
      "metadata": {
        "id": "0xJirDYaKE-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# List of models to evaluate\n",
        "model_names = ['SVM', 'RandomForest', 'XGBoost']\n",
        "\n",
        "for name in model_names:\n",
        "    model = models[name]\n",
        "\n",
        "    # Predict on test set\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n===== {name} Test Evaluation =====\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "s-YEBgXcKaUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebKSwljVKgPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.3 — Deep Learning Models"
      ],
      "metadata": {
        "id": "B1F0IZTHOR7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feedforward Neural Network on Top of BERT Embeddings"
      ],
      "metadata": {
        "id": "KZVf2-pUOSAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step1: Extract BERT Embeddings (Sentence-level)"
      ],
      "metadata": {
        "id": "2DYgt8ObP7ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "\n"
      ],
      "metadata": {
        "id": "CUGoqW_JOhJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####We use sentence-transformers because it produces powerful text embeddings and is excellent for classification."
      ],
      "metadata": {
        "id": "yQGljDXPQE3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Load Arabic-compatible BERT model\n",
        "bert_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "# Convert clean_text into embeddings\n",
        "X_train_emb = bert_model.encode(train_df[\"clean_text\"].tolist(), convert_to_numpy=True)\n",
        "X_val_emb   = bert_model.encode(val_df[\"clean_text\"].tolist(), convert_to_numpy=True)\n",
        "X_test_emb  = bert_model.encode(test_df[\"clean_text\"].tolist(), convert_to_numpy=True)\n",
        "\n",
        "y_train = train_df[\"label\"].values\n",
        "y_val   = val_df[\"label\"].values\n",
        "y_test  = test_df[\"label\"].values\n",
        "\n",
        "print(\"Train embedding shape:\", X_train_emb.shape)"
      ],
      "metadata": {
        "id": "O7RGa-snOiZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PBRblej_PZri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Build a Feedforward Neural Network"
      ],
      "metadata": {
        "id": "GdwUcLEnQRV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Basic feedforward classifier on embeddings\n",
        "ffnn_model = models.Sequential([\n",
        "    layers.Input(shape=(X_train_emb.shape[1],)),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation=\"sigmoid\")   # binary classification\n",
        "])\n",
        "\n",
        "ffnn_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "ffnn_model.summary()"
      ],
      "metadata": {
        "id": "ro7YaeQpQUFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step3: Train the Model"
      ],
      "metadata": {
        "id": "41_gW1QoQnyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ffnn_model.fit(\n",
        "    X_train_emb, y_train,\n",
        "    validation_data=(X_val_emb, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "EPY5esTtQkPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4: Evaluate on Test Set"
      ],
      "metadata": {
        "id": "SJhpebkVQsrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predict\n",
        "y_test_pred = (ffnn_model.predict(X_test_emb) > 0.5).astype(int)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "INoVFVh3QkWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save models\n"
      ],
      "metadata": {
        "id": "ozDCaoD1TGaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zbPKVgBII1Z4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}